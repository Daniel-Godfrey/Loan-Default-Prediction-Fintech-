# -*- coding: utf-8 -*-
"""Loan Default Prediction (Fintech).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DBUXILkP3_G-rMgxm12Lnb6jTZ-0GqDL
"""

#Loan Default Prediction (Fintech) - using fintech_loan_default_dataset.csv
#Author: Daniel Godfrey

"""Loan Default Prediction (Fintech) - using fintech_loan_default_dataset.csv
Author: Daniel Godfrey **bold text**
"""

# Import libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    roc_auc_score, average_precision_score, classification_report,
    confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay
)
import joblib
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

# Load dataset

# Make sure fintech_loan_default_dataset.csv is in the same folder as this script
from google.colab import files
uploaded = files.upload()
df = pd.read_csv("fintech_loan_default_dataset.csv")

print("âœ… Dataset loaded successfully")
print("Shape:", df.shape)
print(df.head())

# Basic EDA
print("\nMissing values per column:")
print(df.isnull().sum())

# Visualize class balance
sns.countplot(x='target_default', data=df)
plt.title("Target Class Distribution (0 = Paid, 1 = Default)")
plt.show()

# Split dataset
X = df.drop(columns=['customer_id', 'target_default'])
y = df['target_default']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.2, random_state=42
)

# Preprocessing pipeline
numeric_features = [
    'age', 'income', 'loan_amount', 'loan_term_months', 'interest_rate',
    'credit_score', 'num_of_products', 'avg_monthly_balance',
    'num_tx_last_30d', 'num_chargebacks', 'days_since_last_login'
]

categorical_features = ['gender', 'employment_type', 'has_previous_default']

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(drop='if_binary', handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)

# Model pipelines
lr_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced'))
])

rf_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(
        n_estimators=200, n_jobs=-1, class_weight='balanced', random_state=42))
])

# Train & evaluate models
def evaluate_model(name, model, X_test, y_test):
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    y_pred = (y_pred_proba >= 0.5).astype(int)
    print(f"\n=== {name} ===")
    print("ROC AUC:", roc_auc_score(y_test, y_pred_proba))
    print("Average Precision (PR AUC):", average_precision_score(y_test, y_pred_proba))
    print("Classification Report:")
    print(classification_report(y_test, y_pred))
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f"{name} - Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()
    RocCurveDisplay.from_predictions(y_test, y_pred_proba)
    plt.title(f"{name} - ROC Curve")
    plt.show()
    PrecisionRecallDisplay.from_predictions(y_test, y_pred_proba)
    plt.title(f"{name} - Precision-Recall Curve")
    plt.show()

# Logistic Regression
lr_pipeline.fit(X_train, y_train)
evaluate_model("Logistic Regression", lr_pipeline, X_test, y_test)

# Random Forest
rf_pipeline.fit(X_train, y_train)
evaluate_model("Random Forest", rf_pipeline, X_test, y_test)

# Save final model
final_model = rf_pipeline
final_model.fit(X, y)  # retrain on full dataset
joblib.dump(final_model, "loan_default_model.pkl")
print("\n Final model saved as loan_default_model.pkl")

# Feature importance (for RandomForest)
preproc = final_model.named_steps['preprocessor']
num_features = numeric_features
cat_encoder = preproc.named_transformers_['cat'].named_steps['onehot']
cat_features = cat_encoder.get_feature_names_out(categorical_features)
feature_names = np.concatenate([num_features, cat_features])
importances = final_model.named_steps['classifier'].feature_importances_

fi = pd.Series(importances, index=feature_names).sort_values(ascending=False).head(20)
print("\nTop 20 Features by Importance:")
print(fi)

fi.plot(kind='barh', figsize=(8, 6))
plt.title("Top 20 Feature Importances - Random Forest")
plt.gca().invert_yaxis()
plt.show()

